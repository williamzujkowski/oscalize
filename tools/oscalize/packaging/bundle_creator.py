"""
Bundle creator for OSCAL artifacts

Creates signed, compressed bundles of OSCAL artifacts for distribution and deployment.
"""

import json
import logging
import tarfile
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from .manifest_generator import ManifestGenerator

logger = logging.getLogger(__name__)


class BundleCreator:
    """Creator for OSCAL artifact bundles"""
    
    def __init__(self):
        self.timestamp = datetime.utcnow().isoformat() + "Z"
        self.manifest_generator = ManifestGenerator()
        
    def create_bundle(self, source_dir: Path, output_file: Path, 
                     include_patterns: Optional[List[str]] = None,
                     compression: str = "gz") -> Path:
        """Create compressed bundle of OSCAL artifacts"""
        logger.info(f"Creating bundle from {source_dir} to {output_file}")
        
        if not source_dir.exists():
            raise ValueError(f"Source directory not found: {source_dir}")
        
        # Ensure output directory exists
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        # Generate manifest
        manifest_data = self.manifest_generator.generate(source_dir, include_patterns)
        
        # Create temporary directory for bundle preparation
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            bundle_dir = temp_path / "oscal-bundle"
            bundle_dir.mkdir()
            
            # Copy files to bundle directory
            self._prepare_bundle_contents(source_dir, bundle_dir, manifest_data)
            
            # Add manifest to bundle
            manifest_file = bundle_dir / "manifest.json"
            with open(manifest_file, 'w') as f:
                json.dump(manifest_data, f, indent=2)
            
            # Add bundle metadata
            bundle_metadata = self._create_bundle_metadata(source_dir, manifest_data)
            metadata_file = bundle_dir / "bundle-metadata.json"
            with open(metadata_file, 'w') as f:
                json.dump(bundle_metadata, f, indent=2)
            
            # Create README
            readme_file = bundle_dir / "README.md"
            self._create_readme(readme_file, bundle_metadata)
            
            # Create compressed bundle
            self._create_compressed_bundle(bundle_dir, output_file, compression)
        
        logger.info(f"Bundle created successfully: {output_file}")
        return output_file
    
    def _prepare_bundle_contents(self, source_dir: Path, bundle_dir: Path, 
                                manifest_data: Dict[str, Any]) -> None:
        """Prepare bundle contents based on manifest"""
        # Create subdirectories
        artifacts_dir = bundle_dir / "artifacts"
        validation_dir = bundle_dir / "validation"
        docs_dir = bundle_dir / "documentation"
        
        artifacts_dir.mkdir()
        validation_dir.mkdir()
        docs_dir.mkdir()
        
        # Copy files based on type
        for file_info in manifest_data["manifest"]["files"]:
            source_file = source_dir / file_info["path"]
            file_type = file_info.get("type", "unknown")
            
            if file_type in ["system-security-plan", "plan-of-action-and-milestones",
                           "assessment-plan", "assessment-results", "component-definition",
                           "profile", "catalog", "oscal-document"]:
                dest_file = artifacts_dir / file_info["path"]
            elif file_type == "validation-log":
                dest_file = validation_dir / file_info["path"]
            else:
                dest_file = docs_dir / file_info["path"]
            
            # Ensure destination directory exists
            dest_file.parent.mkdir(parents=True, exist_ok=True)
            
            # Copy file
            if source_file.exists():
                dest_file.write_bytes(source_file.read_bytes())
    
    def _create_bundle_metadata(self, source_dir: Path, 
                               manifest_data: Dict[str, Any]) -> Dict[str, Any]:
        """Create bundle-level metadata"""
        manifest = manifest_data["manifest"]
        
        bundle_metadata = {
            "bundle": {
                "version": "1.0",
                "created": self.timestamp,
                "creator": "oscalize-bundle-creator",
                "source_directory": str(source_dir),
                "description": "OSCAL artifact bundle generated by oscalize",
                "compliance_standards": [
                    "NIST OSCAL v1.1.3",
                    "OMB M-24-15 automation requirements",
                    "FedRAMP authorization artifacts",
                    "NIST SP 800-53 Rev 5 controls"
                ],
                "contents": self._summarize_bundle_contents(manifest),
                "integrity": manifest.get("integrity", {}),
                "usage_instructions": {
                    "verification": "Use manifest.json to verify artifact integrity",
                    "validation": "Validation logs in validation/ directory show OSCAL compliance",
                    "deployment": "OSCAL artifacts in artifacts/ directory ready for automated processing"
                }
            }
        }
        
        return bundle_metadata
    
    def _summarize_bundle_contents(self, manifest: Dict[str, Any]) -> Dict[str, Any]:
        """Summarize bundle contents"""
        summary = manifest.get("summary", {})
        
        contents = {
            "total_files": summary.get("total_files", 0),
            "oscal_artifacts": summary.get("oscal_artifacts", 0),
            "validation_logs": summary.get("validation_logs", 0),
            "supporting_documents": summary.get("supporting_files", 0),
            "artifact_types": {},
            "validation_status": "See validation logs for detailed status"
        }
        
        # Categorize OSCAL artifacts
        file_types = summary.get("file_types", {})
        for file_type, count in file_types.items():
            if file_type in ["system-security-plan", "plan-of-action-and-milestones",
                           "assessment-plan", "assessment-results", "component-definition"]:
                contents["artifact_types"][file_type.replace("-", "_")] = count
        
        return contents
    
    def _create_readme(self, readme_file: Path, bundle_metadata: Dict[str, Any]) -> None:
        """Create README.md for bundle"""
        bundle_info = bundle_metadata["bundle"]
        
        readme_content = f"""# OSCAL Artifact Bundle

Generated by oscalize on {bundle_info['created']}

## Overview

This bundle contains OSCAL (Open Security Controls Assessment Language) artifacts 
generated from compliance documentation. All artifacts conform to NIST OSCAL v1.1.3 
specifications and support OMB M-24-15 automation requirements.

## Contents

- **artifacts/**: OSCAL JSON artifacts ready for automated processing
- **validation/**: Validation logs from NIST oscal-cli showing compliance status  
- **documentation/**: Supporting documentation and source file references
- **manifest.json**: File integrity manifest with SHA-256 hashes
- **bundle-metadata.json**: Bundle metadata and usage information

## Bundle Statistics

- Total files: {bundle_info['contents']['total_files']}
- OSCAL artifacts: {bundle_info['contents']['oscal_artifacts']}
- Validation logs: {bundle_info['contents']['validation_logs']}
- Supporting documents: {bundle_info['contents']['supporting_documents']}

## Artifact Types

"""
        
        for artifact_type, count in bundle_info['contents']['artifact_types'].items():
            readme_content += f"- {artifact_type.replace('_', ' ').title()}: {count}\n"
        
        readme_content += f"""
## Verification

Verify bundle integrity using the manifest:

```bash
# Using oscalize (recommended)
oscalize verify-manifest manifest.json

# Manual verification  
sha256sum -c <(jq -r '.manifest.files[] | "\\(.hash.value)  \\(.path)"' manifest.json)
```

## Validation Status

All OSCAL artifacts have been validated using NIST oscal-cli. See validation logs 
in the `validation/` directory for detailed results.

## Compliance Standards

This bundle supports:

"""
        
        for standard in bundle_info['compliance_standards']:
            readme_content += f"- {standard}\n"
        
        readme_content += f"""
## Usage

### Automated Processing

OSCAL artifacts in the `artifacts/` directory can be used directly with:
- NIST oscal-cli tools
- FedRAMP automation pipelines  
- Continuous compliance monitoring systems
- Risk management platforms supporting OSCAL

### Manual Review

Human-readable documentation is available in the `documentation/` directory.
Validation results can be reviewed in the `validation/` directory.

## Support

For questions about this bundle or the oscalize tool:
- Review validation logs for specific issues
- Check manifest.json for file integrity
- Refer to NIST OSCAL documentation for format specifications

Generated by oscalize - LLM-free local OSCAL converter
"""
        
        readme_file.write_text(readme_content)
    
    def _create_compressed_bundle(self, bundle_dir: Path, output_file: Path, 
                                 compression: str) -> None:
        """Create compressed tar bundle"""
        # Determine compression mode
        if compression == "gz":
            mode = "w:gz"
        elif compression == "bz2":
            mode = "w:bz2" 
        elif compression == "xz":
            mode = "w:xz"
        else:
            mode = "w"  # No compression
        
        with tarfile.open(output_file, mode) as tar:
            # Add all files in bundle directory
            tar.add(bundle_dir, arcname="oscal-bundle")
    
    def extract_bundle(self, bundle_file: Path, extract_dir: Path) -> Dict[str, Any]:
        """Extract bundle and return metadata"""
        logger.info(f"Extracting bundle {bundle_file} to {extract_dir}")
        
        if not bundle_file.exists():
            raise ValueError(f"Bundle file not found: {bundle_file}")
        
        extract_dir.mkdir(parents=True, exist_ok=True)
        
        # Extract tar bundle
        with tarfile.open(bundle_file, 'r:*') as tar:
            tar.extractall(extract_dir)
        
        # Look for bundle metadata
        bundle_root = extract_dir / "oscal-bundle"
        if not bundle_root.exists():
            # Try without subdirectory
            bundle_root = extract_dir
        
        metadata_file = bundle_root / "bundle-metadata.json"
        if metadata_file.exists():
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)
        else:
            metadata = {"error": "Bundle metadata not found"}
        
        # Verify manifest if present
        manifest_file = bundle_root / "manifest.json"
        if manifest_file.exists():
            verification = self.manifest_generator.verify_manifest(manifest_file)
            metadata["verification"] = verification
        
        logger.info(f"Bundle extracted to {bundle_root}")
        return {
            "extracted_to": str(bundle_root),
            "metadata": metadata
        }
    
    def list_bundle_contents(self, bundle_file: Path) -> List[Dict[str, Any]]:
        """List contents of bundle without extracting"""
        if not bundle_file.exists():
            raise ValueError(f"Bundle file not found: {bundle_file}")
        
        contents = []
        
        with tarfile.open(bundle_file, 'r:*') as tar:
            for member in tar.getmembers():
                if member.isfile():
                    contents.append({
                        "path": member.path,
                        "size": member.size,
                        "modified": datetime.fromtimestamp(member.mtime).isoformat() + "Z",
                        "mode": oct(member.mode)
                    })
        
        return sorted(contents, key=lambda x: x["path"])
    
    def verify_bundle_integrity(self, bundle_file: Path) -> Dict[str, Any]:
        """Verify bundle integrity without full extraction"""
        logger.info(f"Verifying bundle integrity: {bundle_file}")
        
        if not bundle_file.exists():
            return {"valid": False, "error": f"Bundle file not found: {bundle_file}"}
        
        try:
            # Extract just the manifest
            with tempfile.TemporaryDirectory() as temp_dir:
                with tarfile.open(bundle_file, 'r:*') as tar:
                    # Find manifest file
                    manifest_member = None
                    for member in tar.getmembers():
                        if member.name.endswith("manifest.json"):
                            manifest_member = member
                            break
                    
                    if not manifest_member:
                        return {"valid": False, "error": "Manifest not found in bundle"}
                    
                    # Extract and verify manifest
                    tar.extract(manifest_member, temp_dir)
                    manifest_path = Path(temp_dir) / manifest_member.name
                    
                    # Note: Full verification would require extracting all files
                    # This is a basic check that manifest exists and is valid JSON
                    with open(manifest_path, 'r') as f:
                        manifest = json.load(f)
                    
                    return {
                        "valid": True,
                        "manifest_found": True,
                        "file_count": len(manifest.get("manifest", {}).get("files", [])),
                        "note": "Basic integrity check passed. Extract bundle for full verification."
                    }
        
        except Exception as e:
            return {"valid": False, "error": f"Integrity check failed: {str(e)}"}